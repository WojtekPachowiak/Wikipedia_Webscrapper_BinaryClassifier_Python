# -*- coding: utf-8 -*-
"""KlasyfikatorBinarny_1_ZebranieDanych_i_Preprocessing

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bVvb1YBv5zk-9TxPurbykoxB8LvrPM9o
"""

import requests
import bs4
import lxml
import time
from re import sub
import pandas as pd

base_url = 'https://en.wikipedia.org{}'

def Clean_up(str):
  str = str[1:-1]
  str = str.replace('\n',"") 
  str = str.replace('\t',"") 
  str = str.replace('\n,',"") 
  str = str.replace("\\\'","'") 
  str = sub(r"\[\d+\]","",str)
  return str

"""# Zbieranie danych z kategorii "Anthropology""""

categories_ToC_urls = []
categories_ToC_urls.append('https://en.wikipedia.org/w/index.php?title=Category:Anthropology&pageuntil=Metapragmatics#mw-pages')
categories_ToC_urls.append('https://en.wikipedia.org/w/index.php?title=Category:Anthropology&pagefrom=Metapragmatics#mw-pages')
categories_ToC_urls

htmls = []
for url in categories_ToC_urls:
  result = requests.get(url)
  soup = bs4.BeautifulSoup(result.text, "lxml")
  articles_htmls = soup.select('div[id="mw-pages"] li a')
  htmls += articles_htmls

urls = []
for item in htmls:
  urls.append(item['href'])

urls[:10]

anthropo_content = []
for url in urls:
  res = requests.get(base_url.format(url))
  soup = bs4.BeautifulSoup(res.text,'lxml')
  html = soup.select('div[class="mw-parser-output"] p')
  content = bs4.BeautifulSoup(str(html), 'lxml').text
  content = Clean_up(content)
  anthropo_content.append(content)
  time.sleep(5)

data_anthro = pd.DataFrame({'text': anthropo_content, 'label': ['anthro']*len(anthropo_content)})

data_anthro

"""# Zbieranie danych z kategorii "Quantum Mechanics""""

categories_ToC_urls = []
categories_ToC_urls.append('https://en.wikipedia.org/w/index.php?title=Category:Quantum_mechanics&pageuntil=Kicked+rotator#mw-pages')
categories_ToC_urls.append('https://en.wikipedia.org/w/index.php?title=Category:Quantum_mechanics&pagefrom=Kicked+rotator#mw-pages')
categories_ToC_urls.append('https://en.wikipedia.org/w/index.php?title=Category:Quantum_mechanics&pagefrom=Rectangular+Potential+Barrier%0ARectangular+potential+barrier#mw-pages')

categories_ToC_urls

htmls = []
for url in categories_ToC_urls:
  result = requests.get(url)
  soup = bs4.BeautifulSoup(result.text, "lxml")
  articles_htmls = soup.select('div[id="mw-pages"] li a')
  htmls += articles_htmls

urls = []
for item in htmls:
  urls.append(item['href'])

urls[:10]

quantumMech_content = []
for url in urls:
  res = requests.get(base_url.format(url))
  soup = bs4.BeautifulSoup(res.text,'lxml')
  html = soup.select('div[class="mw-parser-output"] p')
  content = bs4.BeautifulSoup(str(html), 'lxml').text
  content = Clean_up(content)
  quantumMech_content.append(content)
  time.sleep(5)

data_quantum = pd.DataFrame({'text': quantumMech_content, 'label': ['quantum']*len(quantumMech_content)})
data_quantum

"""#Łączenie zbiorów danych i ich zapis"""

data = pd.concat([data_anthro,data_quantum],ignore_index=True)
data

data.to_csv('<YOUR_PATH>/WP_badaniaKorpusowe.tsv', index=False, sep ='\t')